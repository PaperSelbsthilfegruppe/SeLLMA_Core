{
    "llm_endpoint": "http://localhost:1234/v1/chat/completions",
    "model_name": "gemma-2-2b-it",
    "max_ram": 16,
    "use_gpu": true,
    "temperature": 0.7,
    "max_tokens": 1024
  }
  